<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>


   <!-- Global site tag (gtag.js) - Google Analytics -->
   <script async src="https://www.googletagmanager.com/gtag/js?id=UA-112020731-1"></script>
   <script>
   window.dataLayer = window.dataLayer || [];
   function gtag(){dataLayer.push(arguments);}
   gtag('js', new Date());

   gtag('config', 'UA-112020731-1');
   </script>

 

  <meta charset="utf-8">
  <title>Yumi's Blog</title>
  <meta name="author" content="Yumi">



  <!-- https://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link href="https://FairyOnIce.github.io/favicon.png" rel="icon">
  <link href="https://FairyOnIce.github.io/theme/css/main.css" media="screen, projection"
rel="stylesheet" type="text/css">
 <link rel="stylesheet" href="https://FairyOnIce.github.io/theme/tipuesearch.css">
  <script src="https://FairyOnIce.github.io/theme/js/modernizr-2.0.js"></script>
  <script src="https://FairyOnIce.github.io/theme/js/ender.js"></script>
  <script src="https://FairyOnIce.github.io/theme/js/octopress.js" type="text/javascript"></script>

  <link href="https://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="https://FairyOnIce.github.io/">Yumi's Blog</a></h1>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>


<form action="https://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:FairyOnIce.github.io" />
    <input class="search" type="text" name="q" results="0"
placeholder="Google Search"/>
  </fieldset>
</form>

<ul class="main-navigation">
    <li><a href="/archives.html">Archives</a></li>
      <li><a href="https://FairyOnIce.github.io/pages/deployment.html">Deployment</a></li>
      <li><a href="https://FairyOnIce.github.io/pages/quest.html">Quest</a></li>
    <li >
    <a href="https://FairyOnIce.github.io/category/blog.html">Blog</a>
    </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div class="blog-index">
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/1D-DCT-vs-2D-DCT.html">What would happen if image is analyzed with 1D-DCT vs 2D-DCT?</a>
      </h1>
      <p class="meta"><time datetime="2019-07-19T21:00:00-07:00" pubdate>Fri 19 July 2019</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the <a href="https://fairyonice.github.io/2D-DCT.html">previous blog</a>, I reviewed 1D-DCT and 2D-DCT. In this blog, I will check what would happen if you denoise the image via 1D-DCT on flattened image.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Denoising">Denoising<a class="anchor-link" href="#Denoising">¶</a></h2><p>I will denoise the image by first transforming an image to frequency domain and pick the top $k$ largest DCT coefficients in absolute values.
The remaining DCT coefficients are sparcified to zero. The new DCT coefficients are then inverse DCTed to spacial domain. The recovered image is visualized.</p></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/1D-DCT-vs-2D-DCT.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/2D-DCT.html">Two-dimensional Discrete Cosine Transform as a Linear Transformation</a>
      </h1>
      <p class="meta"><time datetime="2019-07-01T21:00:00-07:00" pubdate>Mon 01 July 2019</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In previous blog post 
I reviewed <a href="Review on Discrete Fourier Transform">one-dimensional Discrete Fourier Transform (DFT)</a> as well as <a href="https://fairyonice.github.io/Frequency-analysis-of-images-from-scratch.html">two-dimensional DFT</a>. 
This short post is along the same line, and specifically study the following topics:</p>
<ul>
<li>Discrete Cosine Transform</li>
<li>Represent DCT as a linear transformation of measurements in time/spatial domain to the frequency domain.</li>
<li>What would happen if you use 1D DFT on the image, which has two dimensions?</li></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/2D-DCT.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Grad-CAM-with-keras-vis.html">Grad-CAM with keras-vis</a>
      </h1>
      <p class="meta"><time datetime="2019-04-13T20:00:00-07:00" pubdate>Sat 13 April 2019</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/157237655@N08/33777762018/in/datetaken-public/" title="Screen Shot 2019-04-20 at 6.37.26 PM"><img alt="Screen Shot 2019-04-20 at 6.37.26 PM" height="449" src="https://live.staticflickr.com/65535/33777762018_ef034ca758_b.jpg" width="1023" /></a><script async="" charset="utf-8" src="//embedr.flickr.com/assets/client-code.js"></script></p>
<p>Gradient Class Activation Map (Grad-CAM) for a particular category indicates the discriminative image regions used by the CNN to identify that category.</p>
<p>The goal of this blog is to:</p>
<ul>
<li>understand concept of Grad-CAM </li>
<li>understand Grad-CAM is generalization of CAM</li>
<li>understand how to use it using keras-vis</li>
<li>implement it using Keras's backend functions.</li>
</ul>
<h1 id="Reference">Reference<a class="anchor-link" href="#Reference">¶</a></h1><ul>
<li><a href="https://arxiv.org/abs/1610.02391">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</a></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Grad-CAM-with-keras-vis.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Saliency-Map-with-keras-vis.html">Saliency Map with keras-vis</a>
      </h1>
      <p class="meta"><time datetime="2019-04-06T21:00:00-07:00" pubdate>Sat 06 April 2019</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/157237655@N08/40688584023/in/datetaken-public/" title="saliency_map_golden_retriver"><img alt="saliency_map_golden_retriver" height="363" src="https://live.staticflickr.com/65535/40688584023_58640639cc_b.jpg" width="794" /></a><script async="" charset="utf-8" src="//embedr.flickr.com/assets/client-code.js"></script>
Image Specific Class Saliency Visualization allows better understanding of why a model makes a classification decision. The goal of this blog is to understand its concept and how to interpret the Saliency Map.</p>
<h1 id="Reference">Reference<a class="anchor-link" href="#Reference">¶</a></h1><ul>
<li><a href="https://arxiv.org/abs/1312.6034">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</a></li>
<li><a href="https://github.com/raghakot/keras-vis">keras-vis</a></li>
</ul>
<h2 id="Reference-in-this-blog">Reference in this blog<a class="anchor-link" href="#Reference-in-this-blog">¶</a></h2><ul>
<li><a href="https://fairyonice.github.io/Visualization-of-deep-learning-classification-model-using-keras-vis.html">Visualization of deep learning classification model using keras-vis</a></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Saliency-Map-with-keras-vis.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Visualization-of-deep-learning-classification-model-using-keras-vis.html">Visualization of deep learning classification model using keras-vis</a>
      </h1>
      <p class="meta"><time datetime="2019-03-30T20:00:00-07:00" pubdate>Sat 30 March 2019</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the next few blog posts, I will review visualization techiniques.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Image-Specific-Visualization">Image Specific Visualization<a class="anchor-link" href="#Image-Specific-Visualization">¶</a></h2><ul>
<li><a href="https://fairyonice.github.io/Visualization-of-deep-learning-classification-model-using-keras-vis.html">Visualization of deep learning classification model using keras-vis</a></li>
<li><a href="https://fairyonice.github.io/Saliency-Map-with-keras-vis.html">Saliency Map with keras-vis</a></li>
<li><a href="https://fairyonice.github.io/Grad-CAM-with-keras-vis.html">Grad-CAM with keras-vis</a></li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Create-condo-environment">Create condo environment<a class="anchor-link" href="#Create-condo-environment">¶</a></h2>
<pre><code>conda create -n explainableAI python=3.5
source activate explainableAI
conda install tensorflow
conda install keras
conda install jupyter
pip install git+https://github.com/raghakot/keras-vis.git --upgrade --no-deps
pip install opencv-python==3.3.0.10
$CONDA_PREFIX/bin/jupyter notebook --no-browser</code></pre>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Download-a-json-file-containing-ImageNet-class-names.">Download a json file containing ImageNet class names.<a class="anchor-link" href="#Download-a-json-file-containing-ImageNet-class-names.">¶</a></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Visualization-of-deep-learning-classification-model-using-keras-vis.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Step_by_Step_Data_Science_Night_Complete.html">Use pretrained YOLO network for object detection, SJSU data science night</a>
      </h1>
      <p class="meta"><time datetime="2019-01-28T20:00:00-08:00" pubdate>Mon 28 January 2019</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img alt="event_advertisement-1" height="500" src="https://farm8.staticflickr.com/7916/39963452293_57af9e4023.jpg" width="386" />
<a id="Welcome"><h1>Welcome</h1></a></p>
<p>Detecting objects in an image is an important task for machines:</p>
<ul>
<li><p>Self-driving cars need to detect pedestrians and traffic signs on the street; <a href="https://youtu.be/jyevV_rBTt0">Cool YouTube video for ADAS</a></p>
</li>
<li><p>Driving assistant technologies should find the eye's gazing direction to ensure that the driver is focused on driving; <a href="https://youtu.be/Q23K7G1gJgY">Driver Drowsiness Warning System (Ex1)</a>, <a href="https://www.youtube.com/embed/tL_MNBpQDMM?start=118">Driver Drowsiness Warning System (Ex2)</a></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Step_by_Step_Data_Science_Night_Complete.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Step_by_Step_Data_Science_Night_Setup.html">Use pretrained YOLO network for object detection, SJSU data science night (Setup)</a>
      </h1>
      <p class="meta"><time datetime="2019-01-27T20:00:00-08:00" pubdate>Sun 27 January 2019</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img alt="event_advertisement-1" height="500" src="https://farm8.staticflickr.com/7916/39963452293_57af9e4023.jpg" width="386" />
This notebook gives step by step instruction to set up the environment to run the codes <a href="https://fairyonice.github.io/Step_by_Step_Data_Science_Night_Complete.html">Use pretrained YOLO network for object detection, SJSU data science night</a>.</p>
<h1>Table of contents</h1><ul>
<li><a href="#Setup"><h2>Setup environment</h2></a><ul>
<li><a href="#Anaconda 3.7"><h3>Install Anaconda 3.7</h3></a></li>
<li><a href="#Set up virtual environment"><h3>Set up virtual environment</h3></a></li>
<li><a href="#Install python modules"><h3>Install python modules Tensorflow (v1.9.0), Keras (v2.1.2) and opencv3 (v3.4.2)</h3></a></li>
</ul>
</li>
</ul>
<ul>
<li><a href="#Download workshop specific codes"><h2>Download workshop specific codes</h2></a> </li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a id="Setup"><h1>Setup</h1></a>
Please take the following steps in Max OSX (Sorry for Windows users).</p></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Step_by_Step_Data_Science_Night_Setup.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Part_7_Object_Detection_with_Yolo_using_VOC_2012_data_inference_video.html">Part 7 Object Detection with YOLOv2 using VOC 2012 data - inference on video</a>
      </h1>
      <p class="meta"><time datetime="2018-12-30T20:00:00-08:00" pubdate>Sun 30 December 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is the seventh and final blog post of <a href="https://fairyonice.github.io/tag/object-detection-using-yolov2-on-pascal-voc2012-series.html">Object Detection with YOLO blog series</a>. This blog performs inference using the model in trained in <a href="https://fairyonice.github.io/Part_5_Object_Detection_with_Yolo_using_VOC_2012_data_training.html">Part 5 Object Detection with Yolo using VOC 2012 data - training</a>.
I will use PASCAL VOC2012 data. 
This blog assumes that the readers have read the previous blog posts - <a href="https://fairyonice.github.io/Part_1_Object_Detection_with_Yolo_for_VOC_2014_data_anchor_box_clustering.html">Part 1</a></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Part_7_Object_Detection_with_Yolo_using_VOC_2012_data_inference_video.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Part_6_Object_Detection_with_Yolo_using_VOC_2012_data_inference_image.html">Part 6 Object Detection with YOLOv2 using VOC 2012 data - inference on image</a>
      </h1>
      <p class="meta"><time datetime="2018-12-23T20:00:00-08:00" pubdate>Sun 23 December 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/157237655@N08/45817795184/in/datetaken-public/" title="YOLO output example"><img alt="YOLO output example" height="1024" src="https://farm8.staticflickr.com/7832/45817795184_dbfefa974f_b.jpg" width="1022" /></a><script async="" charset="utf-8" src="//embedr.flickr.com/assets/client-code.js"></script></p>
<p>This is the sixth blog post of <a href="https://fairyonice.github.io/tag/object-detection-using-yolov2-on-pascal-voc2012-series.html">Object Detection with YOLO blog series</a>. This blog performs inference using the model in trained in <a href="https://fairyonice.github.io/Part_5_Object_Detection_with_Yolo_using_VOC_2012_data_training.html">Part 5 Object Detection with Yolo using VOC 2012 data - training</a>.
I will use PASCAL VOC2012 data. 
This blog assumes that the readers have read the previous blog posts - <a href="https://fairyonice.github.io/Part_1_Object_Detection_with_Yolo_for_VOC_2014_data_anchor_box_clustering.html">Part 1</a></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Part_6_Object_Detection_with_Yolo_using_VOC_2012_data_inference_image.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="https://FairyOnIce.github.io/Part_5_Object_Detection_with_Yolo_using_VOC_2012_data_training.html">Part 5 Object Detection using YOLOv2 on Pascal VOC2012 - training</a>
      </h1>
      <p class="meta"><time datetime="2018-12-16T20:00:00-08:00" pubdate>Sun 16 December 2018</time></p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/157237655@N08/46489714642/in/datetaken-public/" title="YOLO model training in progress"><img alt="YOLO model training in progress" height="797" src="https://farm8.staticflickr.com/7840/46489714642_d69661a409_b.jpg" width="1024" /></a><script async="" charset="utf-8" src="//embedr.flickr.com/assets/client-code.js"></script></p>
<p>This is the fifth blog post of <a href="https://fairyonice.github.io/tag/object-detection-using-yolov2-on-pascal-voc2012-series.html">Object Detection with YOLO blog series</a>. This blog finally train the model using the scripts that are developed in the <a href="https://fairyonice.github.io/tag/object-detection-using-yolov2-on-pascal-voc2012-series.html">previous blog posts</a>. 
I will use PASCAL VOC2012 data. 
This blog assumes that the readers have read the previous blog posts - <a href="https://fairyonice.github.io/Part_1_Object_Detection_with_Yolo_for_VOC_2014_data_anchor_box_clustering.html">Part 1</a></div>
  <footer>
    <a rel="full-article" href="https://FairyOnIce.github.io/Part_5_Object_Detection_with_Yolo_using_VOC_2012_data_training.html">Read On &crarr;</a>
  </footer>
  		</article>
<div class="pagination">
    <a class="prev" href="https://FairyOnIce.github.io/index2.html">&larr; Older</a>

  <br />
</div></div>
<aside class="sidebar">

<section>
    <h1>Local Search</h1></hr>
    <form class="navbar-search" action="https://FairyOnIce.github.io/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="" name="q" id="tipue_search_input"><input type="submit" value="Go!"></form></li>
</section>
    
<section>

    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://FairyOnIce.github.io/1D-DCT-vs-2D-DCT.html">What would happen if image is analyzed with 1D-DCT vs 2D-DCT?</a>
      </li>
      <li class="post">
          <a href="https://FairyOnIce.github.io/2D-DCT.html">Two-dimensional Discrete Cosine Transform as a Linear Transformation</a>
      </li>
      <li class="post">
          <a href="https://FairyOnIce.github.io/Grad-CAM-with-keras-vis.html">Grad-CAM with keras-vis</a>
      </li>
      <li class="post">
          <a href="https://FairyOnIce.github.io/Saliency-Map-with-keras-vis.html">Saliency Map with keras-vis</a>
      </li>
      <li class="post">
          <a href="https://FairyOnIce.github.io/Visualization-of-deep-learning-classification-model-using-keras-vis.html">Visualization of deep learning classification model using keras-vis</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://FairyOnIce.github.io/category/blog.html">Blog</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="https://FairyOnIce.github.io/tag/bleu.html">BLEU</a>,    <a href="https://FairyOnIce.github.io/tag/deep-learning.html">deep learning</a>,    <a href="https://FairyOnIce.github.io/tag/computer-vision.html">Computer Vision</a>,    <a href="https://FairyOnIce.github.io/tag/nlp.html">NLP</a>,    <a href="https://FairyOnIce.github.io/tag/object-detection-using-yolov2-on-pascal-voc2012-series.html">Object Detection using YOLOv2 on Pascal VOC2012 series</a>,    <a href="https://FairyOnIce.github.io/tag/api.html">API</a>,    <a href="https://FairyOnIce.github.io/tag/pascal-voc2012.html">PASCAL VOC2012</a>,    <a href="https://FairyOnIce.github.io/tag/object-detection-using-rcnn-on-pascal-voc2012-series.html">Object Detection using RCNN on Pascal VOC2012 series</a>,    <a href="https://FairyOnIce.github.io/tag/gps-watch.html">GPS watch</a>,    <a href="https://FairyOnIce.github.io/tag/spectrogram.html">Spectrogram</a>,    <a href="https://FairyOnIce.github.io/tag/heroku.html">Heroku</a>,    <a href="https://FairyOnIce.github.io/tag/object-detection.html">Object Detection</a>,    <a href="https://FairyOnIce.github.io/tag/game.html">Game</a>,    <a href="https://FairyOnIce.github.io/tag/tensorflow.html">TensorFlow</a>,    <a href="https://FairyOnIce.github.io/tag/celeba.html">CelebA</a>,    <a href="https://FairyOnIce.github.io/tag/statistics.html">Statistics</a>,    <a href="https://FairyOnIce.github.io/tag/model.html">Model</a>,    <a href="https://FairyOnIce.github.io/tag/natural-language-processing.html">Natural Language Processing</a>,    <a href="https://FairyOnIce.github.io/tag/fourier-transform.html">Fourier Transform</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/notifications/" target="_blank">LinkedIn</a></li>
            <li><a href="https://github.com/FairyOnIce" target="_blank">Github</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="https://getpelican.com/" target="_blank">Pelican</a></li>
            <li><a href="https://python.org/" target="_blank">Python.org</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Yumi -
  <span class="credit">Powered by <a href="https://getpelican.com">Pelican</a></span>
</p></footer>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-112020731-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'https://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-112020731-1');
    ga('send', 'pageview');
</script>
	<script type="text/javascript">
	  var disqus_shortname = 'yumis-blog';
	  (function() {
	    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
	    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	   })();
	</script>
  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'https://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
</body>
</html>